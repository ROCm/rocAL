{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ff9965",
   "metadata": {},
   "source": [
    " ## Video Pipeline Reading Labelled in rocAL\n",
    "\n",
    "This example presents a simple rocAL video pipeline that loads and decodes video data along with their labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1a3e9",
   "metadata": {},
   "source": [
    " ## Common Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac44489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from amd.rocal.pipeline import Pipeline\n",
    "import amd.rocal.fn as fn\n",
    "import amd.rocal.types as types\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c364e",
   "metadata": {},
   "source": [
    "## Configuring rocAL pipeline\n",
    "Configure the pipeline parameters as required by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20307afc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_path = os.path.join(os.environ['ROCAL_DATA_PATH'], \"video_and_sequence_samples\", \"labelled_videos\")\n",
    "rocal_cpu = True\n",
    "batch_size = 2\n",
    "display = False\n",
    "num_threads = 4\n",
    "random_seed = 1\n",
    "tensor_format = types.NCHW\n",
    "tensor_dtype = types.FLOAT\n",
    "local_rank = 1\n",
    "sequence_length = 3\n",
    "n_iter = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076f0f5",
   "metadata": {},
   "source": [
    "## Defining and Running the Pipeline\n",
    "A custom iterator is created for iterating through the video pipeline outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc73c8-8d31-49c7-92d0-818ef7ef8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCALVideoIterator(object):\n",
    "    \"\"\"\n",
    "    ROCALVideoIterator for pyTorch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pipelines : list of amd.rocal.pipeline.Pipeline\n",
    "                List of pipelines to use\n",
    "    size : int\n",
    "           Epoch size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pipelines, tensor_layout=types.NCHW, reverse_channels=False, multiplier=None, offset=None, tensor_dtype=types.FLOAT, display=False, sequence_length=3):\n",
    "\n",
    "        try:\n",
    "            assert pipelines is not None, \"Number of provided pipelines has to be at least 1\"\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "        self.loader = pipelines\n",
    "        self.tensor_format = tensor_layout\n",
    "        self.multiplier = multiplier if multiplier else [1.0, 1.0, 1.0]\n",
    "        self.offset = offset if offset else [0.0, 0.0, 0.0]\n",
    "        self.reverse_channels = reverse_channels\n",
    "        self.tensor_dtype = tensor_dtype\n",
    "        self.batch_size = self.loader._batch_size\n",
    "        self.rim = self.loader.get_remaining_images()\n",
    "        self.display = display\n",
    "        self.iter_num = 0\n",
    "        self.sequence_length = sequence_length\n",
    "        print(\"____________REMAINING IMAGES____________:\", self.rim)\n",
    "        self.output = self.dimensions = self.dtype = None\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.loader.is_empty():\n",
    "            raise StopIteration\n",
    "\n",
    "        if self.loader.rocal_run() != 0:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self.output_tensor_list = self.loader.get_output_tensors()\n",
    "        self.iter_num += 1\n",
    "        # Copy output from buffer to numpy array\n",
    "        if self.output is None:\n",
    "            self.dimensions = self.output_tensor_list[0].dimensions()\n",
    "            self.dtype = self.output_tensor_list[0].dtype()\n",
    "            self.layout = self.output_tensor_list[0].layout()\n",
    "            self.output = np.empty((self.dimensions[0] * self.dimensions[1], self.dimensions[2], self.dimensions[3], self.dimensions[4]), dtype=self.dtype)\n",
    "        self.output_tensor_list[0].copy_data(self.output)\n",
    "        img = torch.from_numpy(self.output)\n",
    "        self.labels = self.loader.get_image_labels()\n",
    "        return img, self.labels\n",
    "\n",
    "    def reset(self):\n",
    "        self.loader.rocal_reset_loaders()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __del__(self):\n",
    "        self.loader.rocal_release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8bc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(batch_size=batch_size, num_threads=num_threads,device_id=local_rank, seed=random_seed, rocal_cpu=rocal_cpu,\n",
    "                tensor_layout=tensor_format, tensor_dtype=tensor_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c943d",
   "metadata": {},
   "source": [
    "## Video Pipeline\n",
    "Here the video reader is used to read the video data. Then the decoded sequences are passed to CMN. The CMN outputs are returned using set_outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09691217",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pipe:\n",
    "        images = fn.readers.video(file_root=video_path, sequence_length=sequence_length,\n",
    "                               random_shuffle=False, image_type=types.RGB)\n",
    "        crop_size = (512,960)\n",
    "        output_images = fn.crop_mirror_normalize(images,\n",
    "                                                 crop=crop_size,\n",
    "                                                 mean=[0, 0, 0],\n",
    "                                                 std=[1, 1, 1],\n",
    "                                                 mirror=0,\n",
    "                                                 output_dtype=types.UINT8,\n",
    "                                                 output_layout=types.NFHWC)\n",
    "        pipe.set_outputs(output_images)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c42aa",
   "metadata": {},
   "source": [
    "## Building the Pipeline\n",
    "Here the pipeline is created. In order to use this Pipeline, the pipeline has to be built. This is achieved by calling the build function. Then iterator object is created with ROCALVideoIterator(video_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "pipe.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fbd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "data_loader = ROCALVideoIterator(\n",
    "    pipe, multiplier=pipe._multiplier, offset=pipe._offset, display=display, sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8309c7",
   "metadata": {},
   "source": [
    "## Visualizing outputs\n",
    "The outputs of the video sequence are plotted using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa664089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sequence(sequence, labels, count):\n",
    "    columns = 3\n",
    "    rows = (sequence_length + 1) // (columns)\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    if(count % 2 == 0):\n",
    "        plt.suptitle(\"label \" + str(labels[0]), fontsize=30)\n",
    "    for j in range(rows * columns):\n",
    "        plt.subplot(gs[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, (it, labels) in enumerate(data_loader):\n",
    "    if i == 0 or i == 112 or i == 244:\n",
    "        for sequence in it:\n",
    "            display_sequence(sequence, labels, count)\n",
    "            count += 1\n",
    "data_loader.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
